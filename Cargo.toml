[package]
name = "text-splitter"
version = "0.1.0"
authors = ["Ben Brandt <benjamin.j.brandt@gmail.com>"]
edition = "2021"
description = "Split text into semantic chunks, up to a desired chunk size. Supports calculating length by characters and tokens (when used with large language models)."
repository = "https://github.com/benbrandt/text-splitter"
license = "MIT"
keywords = ["text", "split", "tokenizer", "nlp", "ai"]
categories = ["text-processing"]

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
either = "1.8.1"
itertools = "0.10.5"
once_cell = "1.17.1"
regex = "1.7.3"
tiktoken-rs = { version = "0.4.1", optional = true }
tokenizers = { version = "0.13.3", optional = true }
unicode-segmentation = "1.10.1"

[dev-dependencies]
fake = "2.5.0"
insta = { version = "1.29.0", features = ["yaml"] }

[features]
huggingface = ["dep:tokenizers"]
tiktoken = ["dep:tiktoken-rs"]

[profile.dev.package.insta]
opt-level = 3

[profile.dev.package.similar]
opt-level = 3

[profile.dev.package.tiktoken-rs]
opt-level = 3

[profile.dev.package.tokenizers]
opt-level = 3
